# 大数据概念及其处理框架
## 一、[大数据概念](https://www.digitalocean.com/community/tutorials/an-introduction-to-big-data-concepts-and-terminology)
### 1.介绍
大数据是收集，组织，处理和收集大型数据集洞察所需的非传统策略和技术的总称。虽然处理超过单个计算机的计算能力或存储的数据的问题并不新鲜，但近年来这种类型的计算的普遍性，规模和价值已经大大扩展。

在本文中，我们将讨论基础层面的大数据，并定义在研究主题时可能遇到的常见概念。我们还将高级别地了解当前在该领域中使用的一些流程和技术。

### 2.什么是大数据？
“大数据”的确切定义很难确定，因为项目，供应商，从业者和商业专业人士使用它的方式完全不同。考虑到这一点，一般来说，大数据是：
* 大数据集
* 用于处理大型数据集的计算策略和技术的类别   

在此上下文中，“大数据集”表示数据集太大而无法使用传统工具或在单个计算机上合理地处理或存储。这意味着大数据集的共同规模不断变化，并且可能因组织而异。

### 3.为什么大数据系统不同？
使用大数据的基本要求与使用任何大小的数据集的要求相同。然而，在设计解决方案时，大规模，摄取和处理的速度以及在过程的每个阶段必须处理的数据的特征提出了重大的新挑战。大多数大数据系统的目标是从大量异构数据中获得使用传统方法无法实现的洞察力和连接。

2001年，Gartner的Doug Laney首次提出了所谓的“大数据的三个V”来描述使大数据与其他数据处理不同的一些特征：

#### 体积   
处理的信息规模很大，有助于定义大数据系统。这些数据集可以比传统数据集大几个数量级，这需要在处理和存储生命周期的每个阶段进行更多思考。

通常，由于工作要求超出了单台计算机的功能，因此这成为了从计算机组中汇集，分配和协调资源的挑战。能够将任务分解成更小部分的集群管理和算法变得越来越重要。

#### 速度
大数据与其他数据系统显着不同的另一种方式是信息在系统中移动的速度。数据经常从多个来源流入系统，并且通常需要实时处理以获得见解并更新当前对系统的理解。

这种对近乎即时反馈的关注促使许多大数据从业者远离面向批处理的方法，更接近实时流媒体系统。数据不断被添加，按摩，处理和分析，以便跟上新信息的涌入，并在最相关时及早发现有价值的信息。这些想法需要具有高可用组件的强大系统，以防止数据管道中的故障。

#### 品种
大数据问题通常是独特的，因为处理的来源和它们的相对质量都很广泛。

数据可以从内部系统（如应用程序和服务器日志），社交媒体源和其他外部API，物理设备传感器以及其他提供商处获取。大数据旨在通过将所有信息整合到单个系统中来处理潜在有用的数据，而不管它来自何处。

媒体的格式和类型也可能有很大差异。图像，视频文件和录音等富媒体与文本文件，结构化日志等一起被摄取。虽然更传统的数据处理系统可能希望数据进入已标记，格式化和组织的管道，但大数据系统通常接受和存储数据更接近其原始状态。理想情况下，原始数据的任何转换或更改都将在处理时在内存中进行。

#### 其他特点
不同的个人和组织建议扩大原有的三个V，尽管这些提议倾向于描述挑战而不是大数据的质量。一些常见的补充是：

* 准确性：   
各种来源和处理的复杂性可能会导致评估数据质量的挑战（从而导致分析的质量）
* 可变性：   
数据的变化导致质量的广泛变化。可能需要额外的资源来识别，处理或过滤低质量数据以使其更有用。
* 价值：   
大数据的最终挑战是提供价值。有时，现有的系统和流程足够复杂，使用数据和提取实际值可能变得困难。
### 4.大数据生命周期是什么样的？
那么在处理大数据系统时如何实际处理数据呢？虽然实施方法不同，但我们可以谈论的策略和软件有一些共性。虽然下面列出的步骤可能并非在所有情况下都适用，但它们被广泛使用。

涉及大数据处理的一般活动类别是：

* 将数据提取到系统中
* 将数据保存在存储中
* 计算和分析数据
* 可视化结果   

在详细介绍这四个工作流程类别之前，我们将花点时间讨论集群计算，这是大多数大数据解决方案采用的重要策略。建立计算集群通常是每个生命周期阶段使用的技术的基础。

#### 集群计算
由于大数据的质量，个人计算机通常不足以在大多数阶段处理数据。为了更好地满足大数据的高存储和计算需求，计算机集群更适合。

大数据集群软件结合了许多小型机器的资源，力求提供许多好处：

* 资源池：   
结合可用的存储空间来保存数据是一个明显的好处，但CPU和内存池也非常重要。处理大型数据集需要大量所有这三种资源。
* 高可用性：  
群集可以提供不同级别的容错和可用性保证，以防止硬件或软件故障影响对数据和处理的访问。随着我们继续强调实时分析的重要性，这变得越来越重要。
* 易于扩展：   
通过向组中添加其他计算机，集群可以轻松地进行水平扩展。这意味着系统可以对资源需求的变化做出反应，而无需扩展计算机上的物理资源。   

使用群集需要一个解决方案来管理群集成员资格，协调资源共享以及在各个节点上安排实际工作。集群成员资格和资源分配可以由Hadoop的YARN（代表Yet Another Resource Negotiator）或Apache Mesos等软件处理。

组装的计算集群通常充当其他软件与处理数据接口的基础。计算集群中涉及的机器通常也涉及分布式存储系统的管理，我们将在讨论数据持久性时讨论这些问题。   

#### 将数据提取到系统中
数据摄取是获取原始数据并将其添加到系统的过程。此操作的复杂性在很大程度上取决于数据源的格式和质量以及数据在处理之前与期望状态的距离。

可以将数据添加到大数据系统的一种方法是专用摄取工具。Apache Sqoop等技术可以从关系数据库中获取现有数据，并将其添加到大数据系统中。同样，Apache Flume和Apache Chukwa是旨在聚合和导入应用程序和服务器日志的项目。像Apache Kafka这样的排队系统也可以用作各种数据生成器和大数据系统之间的接口。像Gobblin这样的摄取框架可以帮助在摄取管道的末尾聚合和规范化这些工具的输出。

在摄取过程中，通常会进行一定程度的分析，分类和标记。此过程有时称为ETL，表示提取，转换和加载。虽然该术语通常是指遗留数据仓库过程，但是一些相同的概念适用于进入大数据系统的数据。典型的操作可能包括修改传入数据以对其进行格式化，对数据进行分类和标记，过滤掉不需要的或不良的数据，或者可能验证它是否符合某些要求。

考虑到这些功能，理想情况下，捕获的数据应尽可能保持原始状态，以便在管道上进一步提高灵活性。

#### 保持存储中的数据
摄取过程通常将数据交给管理存储的组件，以便可以可靠地持久保存到磁盘。虽然这似乎是一个简单的操作，但是传入数据量，可用性要求和分布式计算层使得更复杂的存储系统成为必需。

这通常意味着利用分布式文件系统进行原始数据存储。像Apache Hadoop的HDFS文件系统这样的解决方案允许在群集中的多个节点上写入大量数据。这确保了计算资源可以访问数据，可以将数据加载到集群的RAM中以进行内存操作，并且可以优雅地处理组件故障。可以使用其他分布式文件系统代替HDFS，包括Ceph和GlusterFS。

还可以将数据导入其他分布式系统，以实现更加结构化的访问。分布式数据库，尤其是NoSQL数据库，非常适合此角色，因为它们通常设计有相同的容错考虑因素，并且可以处理异构数据。有许多不同类型的分布式数据库可供选择，具体取决于您希望如何组织和呈现数据。要了解有关某些选项以及它们最适合用途的更多信息，请阅读我们的NoSQL比较指南。

#### 计算和分析数据
一旦数据可用，系统就可以开始处理数据以显示实际信息。计算层可能是系统中最多样化的部分，因为需求和最佳方法可能会根据所需的洞察类型而有很大差异。数据通常由一个工具迭代地重复处理，或者通过使用许多工具来表示不同类型的见解。

批处理是一种计算大型数据集的方法。该过程包括将工作分成更小的部分，在单个机器上安排每个部件，根据中间结果重新调整数据，然后计算和组装最终结果。这些步骤通常分别称为分裂，映射，改组，缩减和组装，或统称为分布式地图缩减算法。这是Apache Hadoop的MapReduce使用的策略。在处理需要大量计算的非常大的数据集时，批处理最有用。

虽然批处理非常适合某些类型的数据和计算，但其他工作负载需要更多的实时处理。实时处理要求立即处理和准备信息，并要求系统在新信息可用时作出反应。实现此目的的一种方式是流处理，其对由各个项组成的连续数据流进行操作。实时处理器的另一个共同特征是内存计算，它与集群内存中数据的表示一起使用，以避免必须写回磁盘。

Apache Storm，Apache Flink和Apache Spark提供了实现实时或近实时处理的不同方法。这些技术中的每一种都存在权衡，这可能会影响哪种方法最适合任何个别问题。通常，实时处理最适合分析正在快速更改或添加到系统的较小数据块。

以上示例表示计算框架。但是，在大数据系统中还有许多其他计算或分析数据的方法。这些工具经常插入上述框架，并提供额外的接口以与底层进行交互。例如，Apache Hive为Hadoop提供了一个数据仓库接口，Apache Pig提供了一个高级查询接口，而与数据类似的SQL交互可以通过Apache Drill，Apache Impala，Apache Spark SQL和Presto等项目实现。对于机器学习，Apache SystemML，Apache Mahout和Apache Spark的MLlib非常有用。对于在大数据生态系统中得到广泛支持的直接分析编程，R和Python都是受欢迎的选择。

#### 可视化结果
由于在大数据系统中处理的信息类型，随着时间的推移识别数据的趋势或变化通常比值本身更重要。可视化数据是发现趋势和理解大量数据点的最有用方法之一。

实时处理经常用于可视化应用程序和服务器度量标准。数据经常变化，指标中的大量增量通常表明对系统或组织的健康状况产生重大影响。在这些情况下，像Prometheus这样的项目可用于将数据流作为时间序列数据库处理并可视化该信息。

一种流行的数据可视化方法是使用Elastic Stack，以前称为ELK堆栈。由用于数据收集的Logstash，用于索引数据的Elasticsearch和用于可视化的Kibana组成，Elastic堆栈可以与大数据系统一起使用，以便与计算结果或原始指标进行可视化交互。使用Apache Solr进行索引并使用名为Banana的Kibana fork 进行可视化，可以实现类似的堆栈。由这些创建的堆栈称为Silk。

通常用于交互式数据科学工作的另一种可视化技术是数据“笔记本”。这些项目允许以有助于共享，呈现或协作的格式进行数据的交互式探索和可视化。这种可视化界面的流行示例是Jupyter Notebook和Apache Zeppelin。

### 5.大数据词汇表
虽然我们在整个指南中尝试定义概念，但有时在一个地方提供专业术语是有帮助的：

* 大数据：   
大数据是数据集的总称，由于其数量，速度和种类，传统计算机或工具无法合理处理这些数据集。该术语通常也适用于使用此类数据的技术和策略。
* 批处理：   
批处理是一种涉及处理大型数据集的计算策略。这通常适用于对非常大的数据集进行操作的非时间敏感型工作。该过程开始，稍后，系统返回结果。
* 集群计算：   
集群计算是汇集多台计算机资源并管理其集合功能以完成任务的实践。计算机集群需要一个集群管理层来处理各个节点之间的通信并协调工作分配。
* 数据湖：   
数据湖是一个相对原始状态的大型收集数据存储库的术语。这通常用于指在大数据系统中收集的数据，这些数据可能是非结构化的并且经常发生变化。这与数据仓库（下面定义）的精神不同。
数据挖掘：数据挖掘是尝试在大型数据集中查找模式的实践的一个广义术语。这是一个尝试将大量数据细化为更易理解和更有凝聚力的信息的过程。
* 数据仓库：  
数据仓库是大型有序的数据存储库，可用于分析和报告。与数据湖相比，数据仓库由已清理，与其他来源集成的数据组成，并且通常是有序的。数据仓库通常与大数据有关，但通常是更传统系统的组件。
* ETL：  
ETL代表提取，转换和加载。它指的是获取原始数据并为系统使用做好准备的过程。传统上这是与数据仓库相关的过程，但是这个过程的特征也可以在大数据系统的摄取管道中找到。
* Hadoop：   
Hadoop是一个Apache项目，是大数据的早期开源成功。它由一个名为HDFS的分布式文件系统组成，顶部有一个集群管理和资源调度程序，称为YARN（Yet Another Resource Negotiator）。批处理功能由MapReduce计算引擎提供。其他计算和分析系统可以与现代Hadoop部署中的MapReduce一起运行。
* 内存计算：   
内存计算是一种涉及将工作数据集完全移动到集群的集体内存中的策略。中间计算不会写入磁盘，而是保存在内存中。这使像Apache Spark这样的内存计算系统在速度上超过了I / O绑定系统（如Hadoop的MapReduce）的巨大优势。
* 机器学习：   
机器学习是设计系统的研究和实践，可以根据提供给他们的数据来学习，调整和改进。这通常涉及预测和统计算法的实现，当更多数据流过系统时，预测和统计算法可以不断地将“正确”行为和见解归为零。
* Map reduce（大数据算法）：   
Map reduce（大数据算法，而不是Hadoop的MapReduce计算引擎）是一种用于在计算集群上调度工作的算法。该过程涉及拆分问题设置（将其映射到不同的节点）并对它们进行计算以产生中间结果，将结果混洗以对齐类似的集合，然后通过为每个集合输出单个值来减少结果。
* NoSQL：    
NoSQL是一个广义术语，指的是在传统关系模型之外设计的数据库。与关系数据库相比，NoSQL数据库具有不同的权衡，但由于其灵活性和频繁的分布式优先架构，它们通常非常适合大数据系统。
* 流处理：   
流处理是在单个数据项在系统中移动时计算的实践。这允许对馈送到系统的数据进行实时分析，并且对于使用高速度量的时间敏感操作是有用的。
### 6.结论
大数据是一个广泛，快速发展的主题。虽然它并不适合所有类型的计算，但许多组织正在转向某些类型的工作负载的大数据，并使用它来补充现有的分析和业务工具。大数据系统非常适合于表现难以检测的模式，并提供对通过传统方法无法找到的行为的洞察力。通过正确实施处理大数据的系统，组织可以从已有的数据中获得令人难以置信的价值。

## 二、大数据框架对比：Hadoop、Storm、Samza、Spark 和 Flink
### 1.简介
大数据是收集、整理、处理大容量数据集，并从中获得见解所需的非传统战略和技术的总称。虽然处理数据所需的计算能力或存储容量早已超过一台计算机的上限，但这种计算类型的普遍性、规模，以及价值在最近几年才经历了大规模扩展。

本文将介绍大数据系统一个最基本的组件：处理框架。处理框架负责对系统中的数据进行计算，例如处理从非易失存储中读取的数据，或处理刚刚摄入到系统中的数据。数据的计算则是指从大量单一数据点中提取信息和见解的过程。

下文将介绍这些框架：

* 仅批处理框架：   
    * Apache Hadoop
* 仅流处理框架：   
    * Apache Storm
    * Apache Samza
* 混合框架：
    * Apache Spark
    * Apache Flink

### 2.大数据处理框架是什么？
处理框架和处理引擎负责对数据系统中的数据进行计算。虽然“引擎”和“框架”之间的区别没有什么权威的定义，但大部分时候可以将前者定义为实际负责处理数据操作的组件，后者则可定义为承担类似作用的一系列组件。

例如Apache Hadoop可以看作一种以MapReduce作为默认处理引擎的处理框架。引擎和框架通常可以相互替换或同时使用。例如另一个框架Apache Spark可以纳入 Hadoop 并取代 MapReduce。组件之间的这种互操作性是大数据系统灵活性如此之高的原因之一。

虽然负责处理生命周期内这一阶段数据的系统通常都很复杂，但从广义层面来看它们的目标是非常一致的：通过对数据执行操作提高理解能力，揭示出数据蕴含的模式，并针对复杂互动获得见解。

为了简化这些组件的讨论，我们会通过不同处理框架的设计意图，按照所处理的数据状态对其进行分类。一些系统可以用批处理方式处理数据，一些系统可以用流方式处理连续不断流入系统的数据。此外还有一些系统可以同时处理这两类数据。

在深入介绍不同实现的指标和结论之前，首先需要对不同处理类型的概念进行一个简单的介绍。

### 3.批处理系统
批处理在大数据世界有着悠久的历史。批处理主要操作大容量静态数据集，并在计算过程完成后返回结果。

批处理模式中使用的数据集通常符合下列特征...

* 有界：批处理数据集代表数据的有限集合
* 持久：数据通常始终存储在某种类型的持久存储位置中
* 大量：批处理操作通常是处理极为海量数据集的唯一方法

批处理非常适合需要访问全套记录才能完成的计算工作。例如在计算总数和平均数时，必须将数据集作为一个整体加以处理，而不能将其视作多条记录的集合。这些操作要求在计算进行过程中数据维持自己的状态。

需要处理大量数据的任务通常最适合用批处理操作进行处理。无论直接从持久存储设备处理数据集，或首先将数据集载入内存，批处理系统在设计过程中就充分考虑了数据的量，可提供充足的处理资源。由于批处理在应对大量持久数据方面的表现极为出色，因此经常被用于对历史数据进行分析。

大量数据的处理需要付出大量时间，因此批处理不适合对处理时间要求较高的场合。

#### (1) Apache Hadoop
Apache Hadoop 是一种专用于批处理的处理框架。Hadoop 是首个在开源社区获得极大关注的大数据框架。基于谷歌有关海量数据处理所发表的多篇论文与经验的 Hadoop 重新实现了相关算法和组件堆栈，让大规模批处理技术变得更易用。

新版 Hadoop 包含多个组件，即多个层，通过配合使用可处理批数据：

* HDFS：   
HDFS 是一种分布式文件系统层，可对集群节点间的存储和复制进行协调。HDFS 确保了无法避免的节点故障发生后数据依然可用，可将其用作数据来源，可用于存储中间态的处理结果，并可存储计算的最终结果。
* YARN：   
YARN 是 Yet Another Resource Negotiator（另一个资源管理器）的缩写，可充当 Hadoop 堆栈的集群协调组件。该组件负责协调并管理底层资源和调度作业的运行。通过充当集群资源的接口，YARN 使得用户能在 Hadoop 集群中使用比以往的迭代方式运行更多类型的工作负载。
* MapReduce：   
MapReduce 是 Hadoop 的原生批处理引擎。   

**批处理模式**   

Hadoop 的处理功能来自 MapReduce 引擎。MapReduce 的处理技术符合使用键值对的 map、shuffle、reduce 算法要求。基本处理过程包括：

* 从 HDFS 文件系统读取数据集
* 将数据集拆分成小块并分配给所有可用节点
* 针对每个节点上的数据子集进行计算（计算的中间态结果会重新写入 HDFS）
* 重新分配中间态结果并按照键进行分组
* 通过对每个节点计算的结果进行汇总和组合对每个键的值进行“Reducing”
* 将计算而来的最终结果重新写入 HDFS


**优势和局限**   

由于这种方法严重依赖持久存储，每个任务需要多次执行读取和写入操作，因此速度相对较慢。但另一方面由于磁盘空间通常是服务器上最丰富的资源，这意味着 MapReduce 可以处理非常海量的数据集。同时也意味着相比其他类似技术，Hadoop 的 MapReduce 通常可以在廉价硬件上运行，因为该技术并不需要将一切都存储在内存中。MapReduce 具备极高的缩放潜力，生产环境中曾经出现过包含数万个节点的应用。

MapReduce 的学习曲线较为陡峭，虽然 Hadoop 生态系统的其他周边技术可以大幅降低这一问题的影响，但通过 Hadoop 集群快速实现某些应用时依然需要注意这个问题。

围绕 Hadoop 已经形成了辽阔的生态系统，Hadoop 集群本身也经常被用作其他软件的组成部件。很多其他处理框架和引擎通过与 Hadoop 集成也可以使用 HDFS 和 YARN 资源管理器。

**总结** 


Apache Hadoop 及其 MapReduce 处理引擎提供了一套久经考验的批处理模型，最适合处理对时间要求不高的非常大规模数据集。通过非常低成本的组件即可搭建完整功能的 Hadoop 集群，使得这一廉价且高效的处理技术可以灵活应用在很多案例中。与其他框架和引擎的兼容与集成能力使得 Hadoop 可以成为使用不同技术的多种工作负载处理平台的底层基础。

### 4.流处理系统
流处理系统会对随时进入系统的数据进行计算。相比批处理模式，这是一种截然不同的处理方式。流处理方式无需针对整个数据集执行操作，而是对通过系统传输的每个数据项执行操作。

流处理中的数据集是“无边界”的，这就产生了几个重要的影响：

* 完整数据集只能代表截至目前已经进入到系统中的数据总量。
* 工作数据集也许更相关，在特定时间只能代表某个单一数据项。
* 处理工作是基于事件的，除非明确停止否则没有“尽头”。处理结果立刻可用，并会随着新数据的抵达继续更新。   

流处理系统可以处理几乎无限量的数据，但同一时间只能处理一条（真正的流处理）或很少量（微批处理，Micro-batch Processing）数据，不同记录间只维持最少量的状态。虽然大部分系统提供了用于维持某些状态的方法，但流处理主要针对副作用更少，更加功能性的处理（Functional processing）进行优化。

功能性操作主要侧重于状态或副作用有限的离散步骤。针对同一个数据执行同一个操作会或略其他因素产生相同的结果，此类处理非常适合流处理，因为不同项的状态通常是某些困难、限制，以及某些情况下不需要的结果的结合体。因此虽然某些类型的状态管理通常是可行的，但这些框架通常在不具备状态管理机制时更简单也更高效。

此类处理非常适合某些类型的工作负载。有近实时处理需求的任务很适合使用流处理模式。分析、服务器或应用程序错误日志，以及其他基于时间的衡量指标是最适合的类型，因为对这些领域的数据变化做出响应对于业务职能来说是极为关键的。流处理很适合用来处理必须对变动或峰值做出响应，并且关注一段时间内变化趋势的数据。

#### (1)Apache Storm
Apache Storm 是一种侧重于极低延迟的流处理框架，也许是要求近实时处理的工作负载的最佳选择。该技术可处理非常大量的数据，通过比其他解决方案更低的延迟提供结果。

**流处理模式**   
Storm 的流处理可对框架中名为Topology（拓扑）的 DAG（Directed Acyclic Graph，有向无环图）进行编排。这些拓扑描述了当数据片段进入系统后，需要对每个传入的片段执行的不同转换或步骤。

**拓扑包含**：

* Stream：   
普通的数据流，这是一种会持续抵达系统的无边界数据。
* Spout：   
位于拓扑边缘的数据流来源，例如可以是 API 或查询等，从这里可以产生待处理的数据。
* Bolt：   
Bolt 代表需要消耗流数据，对其应用操作，并将结果以流的形式进行输出的处理步骤。Bolt 需要与每个 Spout 建立连接，随后相互连接以组成所有必要的处理。在拓扑的尾部，可以使用最终的 Bolt 输出作为相互连接的其他系统的输入。  

Storm 背后的想法是使用上述组件定义大量小型的离散操作，随后将多个组件组成所需拓扑。默认情况下 Storm 提供了“至少一次”的处理保证，这意味着可以确保每条消息至少可以被处理一次，但某些情况下如果遇到失败可能会处理多次。Storm 无法确保可以按照特定顺序处理消息。

为了实现严格的一次处理，即有状态处理，可以使用一种名为Trident的抽象。严格来说不使用 Trident 的 Storm 通常可称之为Core Storm。Trident 会对 Storm 的处理能力产生极大影响，会增加延迟，为处理提供状态，使用微批模式代替逐项处理的纯粹流处理模式。

为避免这些问题，通常建议 Storm 用户尽可能使用 Core Storm。然而也要注意，Trident 对内容严格的一次处理保证在某些情况下也比较有用，例如系统无法智能地处理重复消息时。如果需要在项之间维持状态，例如想要计算一个小时内有多少用户点击了某个链接，此时 Trident 将是你唯一的选择。尽管不能充分发挥框架与生俱来的优势，但 Trident 提高了 Storm 的灵活性。

**Trident 拓扑包含**：

* 流批（Stream batch）：   
这是指流数据的微批，可通过分块提供批处理语义。
* 操作（Operation）：   
是指可以对数据执行的批处理过程。   

**优势和局限**  

目前来说 Storm 可能是近实时处理领域的最佳解决方案。该技术可以用极低延迟处理数据，可用于希望获得最低延迟的工作负载。如果处理速度直接影响用户体验，例如需要将处理结果直接提供给访客打开的网站页面，此时 Storm 将会是一个很好的选择。

Storm 与 Trident 配合使得用户可以用微批代替纯粹的流处理。虽然借此用户可以获得更大灵活性打造更符合要求的工具，但同时这种做法会削弱该技术相比其他解决方案最大的优势。话虽如此，但多一种流处理方式总是好的。

Core Storm 无法保证消息的处理顺序。Core Storm 为消息提供了“至少一次”的处理保证，这意味着可以保证每条消息都能被处理，但也可能发生重复。Trident 提供了严格的一次处理保证，可以在不同批之间提供顺序处理，但无法在一个批内部实现顺序处理。

在互操作性方面，Storm 可与 Hadoop 的 YARN 资源管理器进行集成，因此可以很方便地融入现有 Hadoop 部署。除了支持大部分处理框架，Storm 还可支持多种语言，为用户的拓扑定义提供了更多选择。

**总结**  
对于延迟需求很高的纯粹的流处理工作负载，Storm 可能是最适合的技术。该技术可以保证每条消息都被处理，可配合多种编程语言使用。由于 Storm 无法进行批处理，如果需要这些能力可能还需要使用其他软件。如果对严格的一次处理保证有比较高的要求，此时可考虑使用 Trident。不过这种情况下其他流处理框架也许更适合。

#### (2)Apache Samza
Apache Samza 是一种与 Apache Kafka 消息系统紧密绑定的流处理框架。虽然 Kafka 可用于很多流处理系统，但按照设计，Samza 可以更好地发挥 Kafka 独特的架构优势和保障。该技术可通过 Kafka 提供容错、缓冲，以及状态存储。

Samza 可使用 YARN 作为资源管理器。这意味着默认情况下需要具备 Hadoop 集群（至少具备 HDFS 和 YARN），但同时也意味着 Samza 可以直接使用 YARN 丰富的内建功能。

**流处理模式**  
Samza 依赖 Kafka 的语义定义流的处理方式。Kafka 在处理数据时涉及下列概念：

* Topic（话题）：    
进入 Kafka 系统的每个数据流可称之为一个话题。话题基本上是一种可供消耗方订阅的，由相关信息组成的数据流。
* Partition（分区）：   
为了将一个话题分散至多个节点，Kafka 会将传入的消息划分为多个分区。分区的划分将基于键（Key）进行，这样可以保证包含同一个键的每条消息可以划分至同一个分区。分区的顺序可获得保证。
* Broker（代理）：   
组成 Kafka 集群的每个节点也叫做代理。
* Producer（生成方）：   
任何向 Kafka 话题写入数据的组件可以叫做生成方。生成方可提供将话题划分为分区所需的键。
* Consumer（消耗方）：   
任何从 Kafka 读取话题的组件可叫做消耗方。消耗方需要负责维持有关自己分支的信息，这样即可在失败后知道哪些记录已经被处理过了。   

由于 Kafka 相当于永恒不变的日志，Samza 也需要处理永恒不变的数据流。这意味着任何转换创建的新数据流都可被其他组件所使用，而不会对最初的数据流产生影响。

**优势和局限**  

乍看之下，Samza 对 Kafka 类查询系统的依赖似乎是一种限制，然而这也可以为系统提供一些独特的保证和功能，这些内容也是其他流处理系统不具备的。

例如 Kafka 已经提供了可以通过低延迟方式访问的数据存储副本，此外还可以为每个数据分区提供非常易用且低成本的多订阅者模型。所有输出内容，包括中间态的结果都可写入到 Kafka，并可被下游步骤独立使用。

这种对 Kafka 的紧密依赖在很多方面类似于 MapReduce 引擎对 HDFS 的依赖。虽然在批处理的每个计算之间对 HDFS 的依赖导致了一些严重的性能问题，但也避免了流处理遇到的很多其他问题。

Samza 与 Kafka 之间紧密的关系使得处理步骤本身可以非常松散地耦合在一起。无需事先协调，即可在输出的任何步骤中增加任意数量的订阅者，对于有多个团队需要访问类似数据的组织，这一特性非常有用。多个团队可以全部订阅进入系统的数据话题，或任意订阅其他团队对数据进行过某些处理后创建的话题。这一切并不会对数据库等负载密集型基础架构造成额外的压力。

直接写入 Kafka 还可避免回压（Backpressure）问题。回压是指当负载峰值导致数据流入速度超过组件实时处理能力的情况，这种情况可能导致处理工作停顿并可能丢失数据。按照设计，Kafka 可以将数据保存很长时间，这意味着组件可以在方便的时候继续进行处理，并可直接重启动而无需担心造成任何后果。

Samza 可以使用以本地键值存储方式实现的容错检查点系统存储数据。这样 Samza 即可获得“至少一次”的交付保障，但面对由于数据可能多次交付造成的失败，该技术无法对汇总后状态（例如计数）提供精确恢复。

Samza 提供的高级抽象使其在很多方面比 Storm 等系统提供的基元（Primitive）更易于配合使用。目前 Samza 只支持 JVM 语言，这意味着它在语言支持方面不如 Storm 灵活。

**总结**   

对于已经具备或易于实现 Hadoop 和 Kafka 的环境，Apache Samza 是流处理工作负载一个很好的选择。Samza 本身很适合有多个团队需要使用（但相互之间并不一定紧密协调）不同处理阶段的多个数据流的组织。Samza 可大幅简化很多流处理工作，可实现低延迟的性能。如果部署需求与当前系统不兼容，也许并不适合使用，但如果需要极低延迟的处理，或对严格的一次处理语义有较高需求，此时依然适合考虑。

### 5.混合处理系统：批处理和流处理
一些处理框架可同时处理批处理和流处理工作负载。这些框架可以用相同或相关的组件和 API 处理两种类型的数据，借此让不同的处理需求得以简化。

如你所见，这一特性主要是由 Spark 和 Flink 实现的，下文将介绍这两种框架。实现这样的功能重点在于两种不同处理模式如何进行统一，以及要对固定和不固定数据集之间的关系进行何种假设。

虽然侧重于某一种处理类型的项目会更好地满足具体用例的要求，但混合框架意在提供一种数据处理的通用解决方案。这种框架不仅可以提供处理数据所需的方法，而且提供了自己的集成项、库、工具，可胜任图形分析、机器学习、交互式查询等多种任务。

#### (1)Apache Spark
Apache Spark 是一种包含流处理能力的下一代批处理框架。与 Hadoop 的 MapReduce 引擎基于各种相同原则开发而来的 Spark 主要侧重于通过完善的内存计算和处理优化机制加快批处理工作负载的运行速度。

Spark 可作为独立集群部署（需要相应存储层的配合），或可与 Hadoop 集成并取代 MapReduce 引擎。

**批处理模式**   

与 MapReduce 不同，Spark 的数据处理工作全部在内存中进行，只在一开始将数据读入内存，以及将最终结果持久存储时需要与存储层交互。所有中间态的处理结果均存储在内存中。

虽然内存中处理方式可大幅改善性能，Spark 在处理与磁盘有关的任务时速度也有很大提升，因为通过提前对整个任务集进行分析可以实现更完善的整体式优化。为此 Spark 可创建代表所需执行的全部操作，需要操作的数据，以及操作和数据之间关系的 Directed Acyclic Graph（有向无环图），即DAG，借此处理器可以对任务进行更智能的协调。

为了实现内存中批计算，Spark 会使用一种名为 Resilient Distributed Dataset（弹性分布式数据集），即RDD的模型来处理数据。这是一种代表数据集，只位于内存中，永恒不变的结构。针对 RDD 执行的操作可生成新的 RDD。每个 RDD 可通过世系（Lineage）回溯至父级 RDD，并最终回溯至磁盘上的数据。Spark 可通过 RDD 在无需将每个操作的结果写回磁盘的前提下实现容错。

**流处理模式**   

流处理能力是由 Spark Streaming 实现的。Spark 本身在设计上主要面向批处理工作负载，为了弥补引擎设计和流处理工作负载特征方面的差异，Spark 实现了一种叫做微批（Micro-batch）*的概念。在具体策略方面该技术可以将数据流视作一系列非常小的“批”，借此即可通过批处理引擎的原生语义进行处理。

Spark Streaming 会以亚秒级增量对流进行缓冲，随后这些缓冲会作为小规模的固定数据集进行批处理。这种方式的实际效果非常好，但相比真正的流处理框架在性能方面依然存在不足。

**优势和局限**   

使用 Spark 而非 Hadoop MapReduce 的主要原因是速度。在内存计算策略和先进的 DAG 调度等机制的帮助下，Spark 可以用更快速度处理相同的数据集。

Spark 的另一个重要优势在于多样性。该产品可作为独立集群部署，或与现有 Hadoop 集群集成。该产品可运行批处理和流处理，运行一个集群即可处理不同类型的任务。

除了引擎自身的能力外，围绕 Spark 还建立了包含各种库的生态系统，可为机器学习、交互式查询等任务提供更好的支持。相比 MapReduce，Spark 任务更是“众所周知”地易于编写，因此可大幅提高生产力。

为流处理系统采用批处理的方法，需要对进入系统的数据进行缓冲。缓冲机制使得该技术可以处理非常大量的传入数据，提高整体吞吐率，但等待缓冲区清空也会导致延迟增高。这意味着 Spark Streaming 可能不适合处理对延迟有较高要求的工作负载。

由于内存通常比磁盘空间更贵，因此相比基于磁盘的系统，Spark 成本更高。然而处理速度的提升意味着可以更快速完成任务，在需要按照小时数为资源付费的环境中，这一特性通常可以抵消增加的成本。

Spark 内存计算这一设计的另一个后果是，如果部署在共享的集群中可能会遇到资源不足的问题。相比 Hadoop MapReduce，Spark 的资源消耗更大，可能会对需要在同一时间使用集群的其他任务产生影响。从本质来看，Spark 更不适合与 Hadoop 堆栈的其他组件共存一处。

**总结**   

Spark 是多样化工作负载处理任务的最佳选择。Spark 批处理能力以更高内存占用为代价提供了无与伦比的速度优势。对于重视吞吐率而非延迟的工作负载，则比较适合使用 Spark Streaming 作为流处理解决方案。

#### (2)Apache Flink
Apache Flink 是一种可以处理批处理任务的流处理框架。该技术可将批处理数据视作具备有限边界的数据流，借此将批处理任务作为流处理的子集加以处理。为所有处理任务采取流处理为先的方法会产生一系列有趣的副作用。

这种流处理为先的方法也叫做Kappa 架构，与之相对的是更加被广为人知的 Lambda 架构（该架构中使用批处理作为主要处理方法，使用流作为补充并提供早期未经提炼的结果）。Kappa 架构中会对一切进行流处理，借此对模型进行简化，而这一切是在最近流处理引擎逐渐成熟后才可行的。

**流处理模型**  

Flink 的流处理模型在处理传入数据时会将每一项视作真正的数据流。Flink 提供的 DataStream API 可用于处理无尽的数据流。Flink 可配合使用的基本组件包括：

* Stream（流）是指在系统中流转的，永恒不变的无边界数据集
* Operator（操作方）是指针对数据流执行操作以产生其他数据流的功能
* Source（源）是指数据流进入系统的入口点
* Sink（槽）是指数据流离开 Flink 系统后进入到的位置，槽可以是数据库或到其他系统的连接器

为了在计算过程中遇到问题后能够恢复，流处理任务会在预定时间点创建快照。为了实现状态存储，Flink 可配合多种状态后端系统使用，具体取决于所需实现的复杂度和持久性级别。

此外 Flink 的流处理能力还可以理解“事件时间”这一概念，这是指事件实际发生的时间，此外该功能还可以处理会话。这意味着可以通过某种有趣的方式确保执行顺序和分组。

**批处理模型**  

Flink 的批处理模型在很大程度上仅仅是对流处理模型的扩展。此时模型不再从持续流中读取数据，而是从持久存储中以流的形式读取有边界的数据集。Flink 会对这些处理模型使用完全相同的运行时。

Flink 可以对批处理工作负载实现一定的优化。例如由于批处理操作可通过持久存储加以支持，Flink 可以不对批处理工作负载创建快照。数据依然可以恢复，但常规处理操作可以执行得更快。

另一个优化是对批处理任务进行分解，这样即可在需要的时候调用不同阶段和组件。借此 Flink 可以与集群的其他用户更好地共存。对任务提前进行分析使得 Flink 可以查看需要执行的所有操作、数据集的大小，以及下游需要执行的操作步骤，借此实现进一步的优化。

**优势和局限**   

Flink 目前是处理框架领域一个独特的技术。虽然 Spark 也可以执行批处理和流处理，但 Spark 的流处理采取的微批架构使其无法适用于很多用例。Flink 流处理为先的方法可提供低延迟，高吞吐率，近乎逐项处理的能力。

Flink 的很多组件是自行管理的。虽然这种做法较为罕见，但出于性能方面的原因，该技术可自行管理内存，无需依赖原生的 Java 垃圾回收机制。与 Spark 不同，待处理数据的特征发生变化后 Flink 无需手工优化和调整，并且该技术也可以自行处理数据分区和自动缓存等操作。

Flink 会通过多种方式对工作进行分许进而优化任务。这种分析在部分程度上类似于 SQL 查询规划器对关系型数据库所做的优化，可针对特定任务确定最高效的实现方法。该技术还支持多阶段并行执行，同时可将受阻任务的数据集合在一起。对于迭代式任务，出于性能方面的考虑，Flink 会尝试在存储数据的节点上执行相应的计算任务。此外还可进行“增量迭代”，或仅对数据中有改动的部分进行迭代。

在用户工具方面，Flink 提供了基于 Web 的调度视图，借此可轻松管理任务并查看系统状态。用户也可以查看已提交任务的优化方案，借此了解任务最终是如何在集群中实现的。对于分析类任务，Flink 提供了类似 SQL 的查询，图形化处理，以及机器学习库，此外还支持内存计算。

Flink 能很好地与其他组件配合使用。如果配合 Hadoop 堆栈使用，该技术可以很好地融入整个环境，在任何时候都只占用必要的资源。该技术可轻松地与 YARN、HDFS 和 Kafka 集成。在兼容包的帮助下，Flink 还可以运行为其他处理框架，例如 Hadoop 和 Storm 编写的任务。

目前 Flink 最大的局限之一在于这依然是一个非常“年幼”的项目。现实环境中该项目的大规模部署尚不如其他处理框架那么常见，对于 Flink 在缩放能力方面的局限目前也没有较为深入的研究。随着快速开发周期的推进和兼容包等功能的完善，当越来越多的组织开始尝试时，可能会出现越来越多的 Flink 部署。

**总结**   

Flink 提供了低延迟流处理，同时可支持传统的批处理任务。Flink 也许最适合有极高流处理需求，并有少量批处理任务的组织。该技术可兼容原生 Storm 和 Hadoop 程序，可在 YARN 管理的集群上运行，因此可以很方便地进行评估。快速进展的开发工作使其值得被大家关注。

### 6.结论
大数据系统可使用多种处理技术。

对于仅需要批处理的工作负载，如果对时间不敏感，比其他解决方案实现成本更低的 Hadoop 将会是一个好选择。

对于仅需要流处理的工作负载，Storm 可支持更广泛的语言并实现极低延迟的处理，但默认配置可能产生重复结果并且无法保证顺序。Samza 与 YARN 和 Kafka 紧密集成可提供更大灵活性，更易用的多团队使用，以及更简单的复制和状态管理。

对于混合型工作负载，Spark 可提供高速批处理和微批处理模式的流处理。该技术的支持更完善，具备各种集成库和工具，可实现灵活的集成。Flink 提供了真正的流处理并具备批处理能力，通过深度优化可运行针对其他平台编写的任务，提供低延迟的处理，但实际应用方面还为时过早。

最适合的解决方案主要取决于待处理数据的状态，对处理所需时间的需求，以及希望得到的结果。具体是使用全功能解决方案或主要侧重于某种项目的解决方案，这个问题需要慎重权衡。随着逐渐成熟并被广泛接受，在评估任何新出现的创新型解决方案时都需要考虑类似的问题。